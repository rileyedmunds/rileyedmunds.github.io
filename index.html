<!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01 Transitional//EN">
<html>
  <head>
  <meta name=viewport content=“width=800”>
  <meta name="generator" content="HTML Tidy for Linux/x86 (vers 11 February 2007), see www.w3.org">
  <style type="text/css">
    /* Color scheme stolen from Sergey Karayev */
    a {
    color: #1772d0;
    text-decoration:none;
    }
    a:focus, a:hover {
    color: #f09228;
    text-decoration:none;
    }
    body,td,th,tr,p,a {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px
    }
    strong {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    }
    heading {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 22px;
    }
    papertitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 14px;
    font-weight: 700
    }
    papersubtitle {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 13px;
    font-weight: 500
    }
    name {
    font-family: 'Lato', Verdana, Helvetica, sans-serif;
    font-size: 32px;
    }
    .img-circle > img{
        margin:auto;
        display:block;
        width: 300px;
        border-radius: 50%;
        vertical-align: middle;
    }
    tr img {
        width: 160px;
    }
    .one
    {
    width: 160px;
    height: 160px;
    position: relative;
    }
    .two
    {
    width: 160px;
    height: 160px;
    position: absolute;
    transition: opacity .2s ease-in-out;
    -moz-transition: opacity .2s ease-in-out;
    -webkit-transition: opacity .2s ease-in-out;
    }
    .fade {
     transition: opacity .2s ease-in-out;
     -moz-transition: opacity .2s ease-in-out;
     -webkit-transition: opacity .2s ease-in-out;
    }
    span.highlight {
        background-color: #ffffd0;
    }
    .header {
		background: no-repeat center center;
		background-image: url(images/japan_garden.jpg);
        background-size: cover;
        overflow: hidden;
        height: 100px;
		max-width: 800px;
		padding-bottom: 0px;
		padding-top: 0px;
		margin-left: auto;
		margin-right: auto;
		margin-bottom: 0px;
		overflow: hidden;
    }
  </style>
  <link rel="apple-touch-icon" sizes="57x57" href="favicon/apple-icon-57x57.png">
  <link rel="apple-touch-icon" sizes="60x60" href="favicon/apple-icon-60x60.png">
  <link rel="apple-touch-icon" sizes="72x72" href="favicon/apple-icon-72x72.png">
  <link rel="apple-touch-icon" sizes="76x76" href="favicon/apple-icon-76x76.png">
  <link rel="apple-touch-icon" sizes="114x114" href="favicon/apple-icon-114x114.png">
  <link rel="apple-touch-icon" sizes="120x120" href="favicon/apple-icon-120x120.png">
  <link rel="apple-touch-icon" sizes="144x144" href="favicon/apple-icon-144x144.png">
  <link rel="apple-touch-icon" sizes="152x152" href="favicon/apple-icon-152x152.png">
  <link rel="apple-touch-icon" sizes="180x180" href="favicon/apple-icon-180x180.png">
  <link rel="icon" type="image/png" sizes="192x192"  href="favicon/android-icon-192x192.png">
  <link rel="icon" type="image/png" sizes="32x32" href="favicon/favicon-32x32.png">
  <link rel="icon" type="image/png" sizes="96x96" href="favicon/favicon-96x96.png">
  <link rel="icon" type="image/png" sizes="16x16" href="favicon/favicon-16x16.png">
  <link rel="manifest" href="/manifest.json">
  <meta name="msapplication-TileColor" content="#ffffff">
  <meta name="msapplication-TileImage" content="favicon/ms-icon-144x144.png">
  <meta name="theme-color" content="#ffffff">
  <title>Riley F. Edmunds</title>
  <meta http-equiv="Content-Type" content="text/html; charset=us-ascii">
  <link href='http://fonts.googleapis.com/css?family=Lato:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
  </head>
  <body>
  <!-- <div class="header"> -->
  <!--     <1!-- <img src="images/japan_garden.jpg"> --1> -->
  <!--     </div> -->
  <table width="800" border="0" align="center" cellspacing="0" cellpadding="0">
    <tr>
    <td>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="67%" valign="middle">
        <p align="center">
          <name>Riley F. Edmunds</name>
        </p>
        <p> I am currently the founder of <a href="https://stride.zone" target="_blank">Stride Labs</a>, a startup building financial applications on blockchains. Before Stride, I spent three years at <a href="https://www.bridgewater.com/research-and-insights/artificial-intelligence" target="_blank">Bridgewater Associates</a> working on machine learning and macro investing. During that time, I also completed a <a href="https://www.depthfirstlearning.com/2020/Resurrecting-Sigmoid" target="_blank">fellowship</a> in deep learning with Google Brain and Jane Street.
        </p>

        <p>
        I received my undergraduate degree in Computer Science from UC Berkeley in Spring 2019. At Berkeley, I was a research assistant in <a href="https://people.eecs.berkeley.edu/~dawnsong/" target="_blank">Dawn Song's Lab</a> (part of <a href="https://bair.berkeley.edu/" target="_blank">BAIR</a>) and <a href="https://me.berkeley.edu/people/alice-m-agogino/" target="_blank">Alice Agogino's Lab</a>. I also built and led the research team at <a href="https://ml.berkeley.edu" target="_blank">Machine Learning at Berkeley</a>, a student organization of 80 members that researches with campus and industry labs and consults with tech companies.
        </p>


        <p>
        While at Berkeley, I contributed to research published at ICRA, IROS, DLSW, and helped write a chapter on Adversarial Machine Learning in the <a target="_blank" href="https://www.amazon.com/Artificial-Intelligence-Security-Chapman-Robotics/dp/0815369824">"Artificial Intelligence Safety and Security"</a>. 
        </p>
        <p align=center>
          <a target="_blank" href="mailto:rileyedmunds@gmail.com">Email</a> &nbsp/&nbsp
          <a target="_blank" href="http://www.github.com/rileyedmunds/"> GitHub </a>&nbsp/&nbsp
          <a target="_blank" href="https://www.linkedin.com/in/rileyedmunds/"> LinkedIn </a>&nbsp/&nbsp
          <a target="_blank" href="https://scholar.google.ca/citations?hl=en&user=PJSVA_QAAAAJ">Scholar</a>
          <!-- &nbsp/&nbsp -->
          <!-- <a href="pdf/resume.pdf"> Resume </a> -->
        </p>
        </td>
        <td width="33%" class="img-circle">
            <img src='./images/headshot.png'>
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td width="100%" valign="middle">
          <heading>Publications</heading>
          <!-- <p> -->
          <!-- I'm interested in computer vision, machine learning, statistics, optimization, image processing, virtual reality, and computational photography. Much of my research is about inferring the physical world (shape, depth, motion, paint, light, colors, etc) from images. I have also worked in astronomy and biology. Representative papers are <span class="highlight">highlighted</span>. -->
          <!-- </p> -->
        </td>
      </tr>
      </table>

      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr >
          <td width="25%">
            <img width=160px src='./images/dfl_diagram.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://www.depthfirstlearning.com/2020/Resurrecting-Sigmoid">
                <papertitle>2019 Jane Street Fellowship: Resurrecting the Sigmoid</papertitle>

          </a>
          <br>
              Piyush Patil,
              Vinay Ramasesh,
              <strong>Riley F. Edmunds</strong>
              <br>
              <em>2019, New York City</em><br>
            <p>Co-wrote and taught class on signal propagation & random matrix theory in deep neural networks as a 2019 Jane Street Fellow. Depth First Learning is a collaboration between NYU, FAIR, DeepMind, and Google Brain. Learn more <a target="_blank" href="https://fellowship.depthfirstlearning.com/">here</a>.</p>
          </td>
        </tr>

  <!-- --- -->
        <tr >
          <td width="25%">
            <img width=160px src='./images/bridgewater.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://www.bridgewater.com/research-and-insights/reflation-in-warp-speed">
                <papertitle>Reflation in Warp Speed</papertitle>

          </a>
          <br>
              Greg Jensen,
              Mark Dinner,
              Melissa Saphier,
              <strong>Riley F. Edmunds</strong>
              <br>
              <em>Bridgewater Associates, July 2020</em><br>
            <p>One of my first research reports at Bridgewater. Analysis of the unprecedented speed and magnitude of policy response to the COVID-19 crisis, comparing the timeline of asset reflation across the Great Depression, Global Financial Crisis, and current pandemic.</p>
          </td>
        </tr>

  <!-- --- -->
        <tr >
          <td width="25%">
            <img width=160px src='./images/icra2018.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/icra2018.pdf">
                <papertitle>Tensegrity Robot Locomotion under Limited Sensory Inputs via Deep Reinforcement Learning</papertitle>

          </a>
          <br>
              Jianlan Luo,
              <strong> Riley F. Edmunds</strong>,
              Franklin Rice,
              <a target="_blank" href="http://best.berkeley.edu/wp-content/uploads/2015/08/CV_Agogino.pdf">Alice M. Agonino</a>
              <br>
              <em>International Conference on Robotics and Automation (ICRA), 2018</em><br>
            <a target="_blank" href="pdf/icra2018.pdf">PDF</a>
            /
            <a target="_blank" href="https://www.youtube.com/watch?v=rA-YGcnnha4&t=">Video</a>
            <p>Work demonstrating that Tensegrity robots can learn locomotion policies even with severely limited sensory inputs using Mirror Descent Guided Policy Search (MDGPS). </p>
          </td>
        </tr>

  <!-- --- -->
        <tr >
            <td width="25%"     style="text-align: center;">
            <img height=160px src='./images/aisafety.jpg'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://drive.google.com/file/d/1rzoyGXS-Wzqm-N7CzNKXpVut8oCq7Oz7/view">
                <papertitle>Artificial Intelligence Safety and Security</papertitle>

          </a>
                <br>
                <papersubtitle>Chapter on Adversarial Machine Learning</papersubtitle>
          <br>
              <a target="_blank" href="http://philkuz.com/">Phillip Kuznetsov</a>,
              <strong>Riley F. Edmunds</strong>,
              <a target="_blank" href="http://tedxiao.me/">Ted Xiao</a>,
              Humza Iqbal,
              <a target="_blank" href="https://www.linkedin.com/in/raul-puri-3a0b43a0">Raul Puri</a>, 
              <a target="_blank" href="http://noahgolmant.com/">Noah Golmant</a>,
              <a target="_blank" href="http://shannonsh.github.io/">Shannon Shih</a>
              <br>
              <em>CRC Press 2018 </em><br>
            <a target="_blank" href="https://www.crcpress.com/Artificial-Intelligence-Safety-and-Security/Yampolskiy/p/book/9780815369820">Book</a>
            /
            <a target="_blank" href="https://drive.google.com/file/d/1rzoyGXS-Wzqm-N7CzNKXpVut8oCq7Oz7/view">Chapter</a>
            <p></p>
            <p>Chapter surveying the field of Adversarial Machine Learning with connections to AI Safety.</p>
          </td>
        </tr>

      <!-- --- -->
         <tr onmouseout="trans_stop()" onmouseover="trans_start()">
          <td width="25%">
            <div class="one">
        <div class="two" id="trans_image" style="opacity: 0;">
                    <img src="./images/transfer1.png">
                </div>
                <img src="./images/transfer2.png">
            </div> 
            <script type="text/javascript">
                function trans_start() {
                    document.getElementById('trans_image').style.opacity = "1";
            
                }
                function trans_stop() {
                    document.getElementById('trans_image').style.opacity = "0";
                            
                }
                trans_stop()
            </script>
          </td>
          <td valign="top" width="75%">
        <!-- <tr >
          <td width="25%">
            <img width=160px src='images/transfer1.png'>
          </td>
          <td valign="top" width="75%"> -->
          <a target="_blank" href="pdf/dlsw2017.pdf">
                <papertitle>Transferability of Adversarial Attacks in Model-Agnostic Meta-Learning</papertitle>

          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              <a target="_blank" href="http://noahgolmant.com/">Noah Golmant</a>,
              Vinay Ramasesh,
              <a target="_blank" href="http://philkuz.com/">Phillip Kuznetsov</a>,
              Piyush Patil,
              Raul Puri
              <br>
              <em>Deep Learning and Security Workshop (DLSW) in Singapore, 2017</em><br>
            <a target="_blank" href="pdf/dlsw2017.pdf">PDF</a>
            /
            <a target="_blank" href="https://docs.google.com/presentation/d/13JAGGmO_NF6lMy47Xborx9xcwr94_K5N57sAYivgIvw/edit?usp=sharing">Slides</a>
            <p>Work desmonstrating that in a Meta-Learning context, adversarial attacks transfer between networks trained on different classification tasks drawn from Omniglot and mini-ImageNet.</p>
          </td>
        </tr>
                <!-- --- -->



<!-- --- -->

      <!-- --- -->
         <!-- <tr onmouseout="expand_stop()" onmouseover="expand_start()"> -->
         <!--  <td width="25%"> -->
         <!--    <div class="one"> -->
        <!-- <div class="two" id="expand_image" style="opacity: 0;"> -->
         <!--            <img src="images/expand_1.png"> -->
         <!--        </div> -->
         <!--        <img src="images/expand_2.png"> -->
         <!--    </div> --> 
         <!--    <script type="text/javascript"> -->
         <!--        function expand_start() { -->
         <!--            document.getElementById('expand_image').style.opacity = "1"; -->
            
         <!--        } -->
         <!--        function expand_stop() { -->
         <!--            document.getElementById('expand_image').style.opacity = "0"; -->
                            
         <!--        } -->
         <!--        expand_stop() -->
         <!--    </script> -->
         <!--  </td> -->
         <!--  <td valign="top" width="75%"> -->
        <tr >
          <td width="25%">
            <img width=160px src='images/expand.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/iat2017.pdf">
                <papertitle>Hierarchical Semi-Supervised Embeddings for Anomaly Detection</papertitle>

          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              <a target="_blank" href="http://noahgolmant.com/">Efraim Feinstein</a>
              <br>
              <em>Intuit I.A.T. 2017</em><br>
            <a target="_blank" href="pdf/iat2017.pdf">PDF</a>
            <p>A semi-supervised autoencoder model for fraud detection in event-streams having unbalanced class sizes and concept drift. Filed patent application based on invention.</p>
          </td>
        </tr>

<!-- --- -->

        <!-- <tr > -->
       <!--  <tr onmouseout="roll_stop()" onmouseover="roll_start()">
          <td width="25%">
            <div class="one">
        <div class="two" id="roll_image" style="opacity: 0;">
                    <img src="images/roll2.png">
                </div>
                <img src="images/roll1.png">
            </div> 
            <script type="text/javascript">
                function roll_start() {
                    document.getElementById('roll_image').style.opacity = "1";
            
                }
                function roll_stop() {
                    document.getElementById('roll_image').style.opacity = "0";
                            
                }
                roll_stop()
            </script>
          </td>
          <td valign="top" width="75%"> -->
          <td width="25%">
            <img width=160px src='./images/roller.gif'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/iros2017.pdf">
                <papertitle>Inclined Surface Locomotion Strategies for Spherical Tensegrity Robots</papertitle>

          </a>
          <br>
              Lee-Huang Chen,
              Brian Cera,
              Edward L. Zhu,
              <strong>Riley F. Edmunds</strong>,
              Franklin Rice, 
              Antonia Bronars, 
              Ellande Tang, 
              Saunon R. Malekshahi, 
              Osvaldo Romero, 
              <a target="_blank" href="https://ti.arc.nasa.gov/profile/aagogino/">Adrian K. Agogino</a>, 
              <a target="_blank" href="http://best.berkeley.edu/wp-content/uploads/2015/08/CV_Agogino.pdf">Alice M. Agonino</a>
              <br>
              <em>International Conference on Intelligent Robots and Systems (IROS), 2017</em><br>
            <a target="_blank" href="pdf/iros2017.pdf">PDF</a>
            /
            <a target="_blank" href="https://www.youtube.com/watch?v=sqqOZ4Sg95Q">Video</a>
            <p>The first tensegrity robot to achieve reliable locomotion on inclined surfaces of up to 24 degrees, with two novel multi-cable actuation policies, suited for steep incline climbing and speed, respectively.</p>
          </td>
        </tr>



        <!-- --- -->

        <td>
        <heading>Projects</heading>
        </td>
    <!-- </tr> -->

    <!-- --- -->
<!-- 
      <a target="_blank" href="https://ml.berkeley.edu">
                <papertitle>Machine Learning at Berkeley</papertitle>
          </a>
          <br>
            <p>For two years, guided Machine Learning at Berkeley's research projects towards publication (15+ published papers at NeurIPS, ICML, ICLR, and ICCV), and publicity (talks, poster sessions, hosting speakers including Ian Goodfellow and Andrej Karpathy). Developed working relationships with academic partners (BAIR, ICSI) and industry research collaborators (Google Brain, OpenAI).</p>
 -->




        <!-- ---- -->
        <tr >
          <td width="25%">
            <img width=160px src='./images/mlab.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://ml.berkeley.edu">
                <papertitle>Research @ Machine Learning at Berkeley</papertitle>

          </a>
          <br>
            <p>For two years, built and led Machine Learning at Berkeley's research arm.
            We published 15+ papers at NeurIPS, ICML, ICLR, and ICCV. We hosted talks, poster sessions, with speakers including Ian Goodfellow and Andrej Karpathy. Developed working relationships with academic partners (BAIR, ICSI) and industry research collaborators (Google Brain, OpenAI).
              </p>
          </td>
        </tr>

        <!-- ---- -->
    <!-- --- -->

        <tr >
          <td width="25%">
            <img width=160px src='./images/cardioid.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://github.com/pvirtue/caffe/tree/complex">
                <papertitle>Complex-Valued Neural Networks</papertitle>

          </a>
          <br>
              Pat Virtue,
              <strong>Riley F. Edmunds</strong>,
              Vinay Ramasesh,
              Renee Sweeney, 
              <a target="_blank" href="http://www1.icsi.berkeley.edu/~stellayu/">Stella Yu</a> 
              <br>
            <a target="_blank" href="https://github.com/pvirtue/caffe/tree/complex">Github</a>
            <p>We derived and implemented novel complex-valued layer functions for Convolutional Neural Networks, testing performance on frequency-domain problems: representation learning on MRI data and classification of SAR (Radar) data.</p>
          </td>
        </tr>

        <!-- ---- -->

        <tr >
          <td width="25%">
            <img width=160px src='./images/aedist_.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/aedist.pdf">
                <papertitle>Learning Transferability Metrics Across Tasks</papertitle>

          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              Jianlan Luo*
              <br>
            <a target="_blank" href="pdf/aedist.pdf">PDF</a>
            <p>Work towards learning empirical transferability metrics between reinforcement learning tasks using autoencoder reconstruction errors and Model-Agnostic Meta-Learning.</p>
          </td>
        </tr>

        <!-- ---- -->

         <!-- ---- -->

        <tr >
          <td width="25%">
            <img width=160px src='./images/archsearch.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/archsearch_post.pdf">
                <papertitle>Survey of Neural Architecture Search</papertitle>

          </a>
          <br>
              <strong>Riley F. Edmunds</strong>
              <br>
            <a target="_blank" href="pdf/archsearch_post.pdf">PDF</a>
            <p>A blog post on Neural Architecture Search's applications in Deep Learning, with an emphasis on crafting Domain Specific Languages to encode expressive yet tractable search spaces.</p>
          </td>
        </tr>

        <!-- --- -->

        <tr onmouseout="inpainting_stop()" onmouseover="inpainting_start()">
          <td width="25%">
            <div class="one">
        <div class="two" id="inpainting_image" style="opacity: 0;">
                    <img src="./images/gp2.png">
                </div>
                <img src="./images/gp1.png">
            </div> 
            <script type="text/javascript">
                function inpainting_start() {
                    document.getElementById('inpainting_image').style.opacity = "1";
            
                }
                function inpainting_stop() {
                    document.getElementById('inpainting_image').style.opacity = "0";
                            
                }
                inpainting_stop()
            </script>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="pdf/distill_bo.pdf">
                <papertitle>Tutorial on Bayesian Optimization</papertitle>
          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              Rahil Mathur
          <br>

          <a target="_blank" href="pdf/distill_bo.pdf">PDF</a>
          <br>
            <p> A tutorial on Bayesian Optimization and its applications in Deep Learning, with a focus on providing as much intuition behind the underlying theory as possible.
            </p>
          </td>
        </tr>

        <!-- ---- -->

        <tr >
          <td width="25%">
            <img width=160px src='./images/carillon.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://www.youtube.com/watch?v=gUPY_vwpJaQ">
                <papertitle>VR Virtual Campanile</papertitle>

          </a>
          <br>
              Yulin Zheng,
              James Lin,
              <strong>Riley F. Edmunds</strong>,
              Kyle Provencher
              <br>
            <a target="_blank" href="https://www.youtube.com/watch?v=gUPY_vwpJaQ">Video</a>
            <p>Using the Unity game engine and the HTC Vive, we created a 3D modeled virtual version of the UC Berkeley Campanile along with an interactive carillon.</p>
          </td>
        </tr>

        <!-- ---- -->
        <tr >
          <td width="25%">
            <img width=160px src='./images/capsulelogo.png'>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://fnd.io/#/us/ios-universal-app/1080346513-capsule-travel-the-world-through-photos-">
                <papertitle>Capsule - Travel the World through Photos</papertitle>

          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              Connor Killion,
              Aparna Krishnan
              <br>
            <a target="_blank" href="https://fnd.io/#/us/ios-universal-app/1080346513-capsule-travel-the-world-through-photos-">iOS App</a>
            <p>Capsule connects the world through pictures. Travel to real world locations, pick up a capsule, and view images of everywhere else it's been. When you're done, travel somewhere else, take a picture, and leave it there for future explorers. Run up your score with frequent contributions, or use those points to add new capsules to the world. Happy travels!</p>
          </td>
        </tr>


      </table>


      <!-- <tr>
        <td>
        <heading>Speaking</heading>
        </td>

        <tr onmouseout="inpainting_stop()" onmouseover="inpainting_start()">
          <td width="25%">
          	<div class="one">
				<div class="two" id="inpainting_image" style="opacity: 0;">
                    <img src="images/texture_cue_output.png">
                </div>
                <img src="images/texture_cue_input.png">
            </div> 
            <script type="text/javascript">
                function inpainting_start() {
                    document.getElementById('inpainting_image').style.opacity = "1";
            
                }
                function inpainting_stop() {
                    document.getElementById('inpainting_image').style.opacity = "0";
                            
                }
                inpainting_stop()
            </script>
          </td>
          <td valign="top" width="75%">
          <a href="https://philkuz.github.io/184final/">
                <papertitle>Extrapolating Texture from Texture Cues</papertitle>
          </a>
          <br>
              <strong>Riley F. Edmunds</strong>,
              Stefan Palombo,
              Gabriel Gardner,
              Rahil Mathur,
              Michael Luo
          <br>

          <a href="https://philkuz.github.io/184final/">Project Website</a>
          <br>
            <p> We attempt to apply textures automatically to non-textured images of 3d renderings using convolutional neural networks as a final step in a graphics pipeline. Our final product is a system in which you can pass an untextured rendering with a texture cue into a trained convolutional neural network that then outputs a fully textured result.
            </p>
          </td>
        </tr>

        <tr>
          <td width="25%">
            
            <img src='images/cans.png' width=160px>
          </td>
          <td valign="top" width="75%">
          <a href="https://github.com/mlberkeley/Creative-Adversarial-Networks">
                <papertitle>Creative Adversarial Networks</papertitle>
          </a>
          <br>
          <a href="https://github.com/mlberkeley/Creative-Adversarial-Networks">Github</a>
          <br>
            <p>First Open-source Implementation of Creative Adversarial Networks. Adapts
            the Generative Adversarial Network objective function to try to maximize the entropy
            for a style-class distribution, while also minimizing the original 
            adversarial objective.</p>
          </td>
        </tr>
        <tr onmouseout="compress_stop()" onmouseover="compress_start()">
          <td width="25%">
          	<div class="one">
				<div class="two" id="compress_image" style="opacity: 0;">
                    <img src="images/monkey_compress.jpg">
                </div>
                <img src="images/monkey_og.jpg">
            </div> 
            <script type="text/javascript">
                function compress_start() {
                    document.getElementById('compress_image').style.opacity = "1";
            
                }
                function compress_stop() {
                    document.getElementById('compress_image').style.opacity = "0";
                            
                }
                compress_stop()
            </script>
          </td>
          <td valign="top" width="75%">
                <papertitle>Image Compression by Abstracting out Details</papertitle>
          <br>
            <a href="pdf/ablative.pdf">PDF</a>
            <p> We propose a method to apply a pre-trained Generative Adversarial Networks to 
            image compression. The proposed method removes significant portions of an image 
            while retaining some assistant information, and fills the gaps using generative 
            model inpainting. We use Plug and Play Generative Networks as our inpainting 
            network, and explore several different ablation schemes in order to determine 
            the most useful information present in an image, according to the quality
            of the reconstruction.</p>
          </td>
        </tr>
        <tr>
          <td width="25%">
            
            <img src='images/openbrain.png' width=160px>
          </td>
          <td valign="top" width="75%">
          <a href="https://github.com/mlberkeley/openbrain">
              <papertitle>Asynchronous Hebbian Learning</papertitle>
          </a>
          <br>
          <a href="https://www.youtube.com/watch?v=vOHumxida9M">Minecraft Demo</a> &nbsp/&nbsp
          <a href="https://github.com/mlberkeley/openbrain"> GitHub </a>
          <br>
            <p>Asynchronous neural network implementation using Hebbian learning rules. Later adapted to replace local Hebbian rules with RL approach based on DDPG.</p>
          </td>
        </tr>
        <tr>
          <td width="25%">
            
            <img src='images/raspi.jpeg' width=160px>
          </td>
          <td valign="top" width="75%">
          <a href="https://ml.berkeley.edu">
                <papertitle>Raspberry PI cluster</papertitle>
          </a>
          <br>
            <p>Multiple node cluster built out of 32 Raspberry PI B+. Networked together using a standard network switch. Bootstrapped a custom power supply
            originall intended for Christmas lights. Utilized Erlang to communicate between the compute nodes and run the above algorithm across all machines.
          </td>
        </tr>

      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      <tr>
        <td>
        <heading>Speaking</heading> -->


        <!-- “Deep Hierarchical Semi-Supervised Embeddings for Dynamic Targeted Anomaly Detection.” Intuit I.A.T. Lab, August 2017. 

“Tunable Efficient Unitary Neural Networks.” International Computer Science Institute (ICSI), July 2017. 

“Simons Institute: Representation Learning.” Intuit IAT Lab, July 2017. 

“Complex-Valued Deep Neural Networks: Activation Functions.” Machine Learning at Berkeley, May 2017. 

“Complex-Valued Deep Neural Networks”. Machine Learning at Berkeley, January 2017. 

“Sound Classification with Complex Valued Neural Networks.” Machine Learning at Berkeley, November 2016. 

“Environmental Sound Classification with Convolutional Neural Networks.” International Computer Science Institute, September 2016. -->
<!-- 
        </td>
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellpadding="20">
      <tr>
        <td width="25%"><img src="images/mlab.png" width="160" height="160"></td>
        <td width="75%" valign="center">
        <p>
          <a href="https://github.com/mlberkeley/Machine-Learning-Decal-Spring-2018">
          <papertitle>Machine Learning Decal</papertitle>
          </a>
          <!-- TODO add description of machine learning decal -->
          <!-- <br><br>
          <a href="http://inst.eecs.berkeley.edu/~cs188/sp11/announcements.html">
          <papertitle>Workshops</papertitle>
          </a -->
          <!--- TODO post GANS -->
          <!--- TODO post Style Transfer -->
          <!--- TODO post Intro to Deep Learning -->


<!-- 
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
      </tr>
      </table>
      <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">
        <tr>
          <td width="25%">
            <img src='images/mlab.png' width=160px>
          </td>
          <td valign="top" width="75%">
          <a target="_blank" href="https://ml.berkeley.edu">
                <papertitle>Machine Learning at Berkeley</papertitle>
          </a>
          <br>
            <p>VP of Research of UC Berkeley's first Machine Learning student organization from April 2017 to May 2018. Project manager August 2016 to Present.</p>
          </td>
        </tr>    
          
          <br>
        </p>
        </td>
      </tr>
      </table> -->
<!-- 
      <td>
      <heading>Talks</heading>
      </td> -->


<!-- --- TALKS START --- -->
     <!--  <table width="95%" align="center" border="0" cellspacing="0" cellpadding="20">
      <td>
      <heading>Talks</heading>
      </td>
      <tr>
        <td width="67%" valign="middle">

        <p> 
      “Deep Hierarchical Semi-Supervised Embeddings for Dynamic Targeted Anomaly Detection.” Intuit IAT, August 2017. 
      </p><p>

      “Tunable Efficient Unitary Neural Networks.” International Computer Science Institute (ICSI), July 2017. 
      </p><p>
      “Simons Institute: Representation Learning.” Intuit IAT, July 2017. 
</p><p>
      “Complex-Valued Deep Neural Networks: Activation Functions.” Machine Learning at Berkeley, May 2017. 
</p><p>
      “Complex-Valued Deep Neural Networks”. Machine Learning at Berkeley, January 2017. 
</p><p>
      “Sound Classification with Complex Valued Neural Networks.” Machine Learning at Berkeley, November 2016. 
</p><p>
      “Environmental Sound Classification with CNNs.” International Computer Science Institute, September 2016.
        </p>
        <p align=center>

        </p>
        </td>


      </tr>
      </table> -->
<!-- --- TALKS END --- -->


            </tr>
      </table>

      <!-- <tr >

          <table width="100%" align="center" border="0" cellspacing="0" cellpadding="20">

          <td valign="top" width="75%", align="center">
          <br>
              “Deep Hierarchical Semi-Supervised Embeddings for Dynamic Targeted Anomaly Detection.” Intuit I.A.T. Lab, August 2017,

              “Tunable Efficient Unitary Neural Networks.” International Computer Science Institute (ICSI), July 2017.,


              <br>
              <em>Intuit I.A.T. 2017</em><br>
            <a target="_blank" href="pdf/iat2017.pdf">PDF</a>
            <p>Work demonstrating anomaly detection with semi-supervised autoencoders.</p>
          </td>
        </tr>

      “Deep Hierarchical Semi-Supervised Embeddings for Dynamic Targeted Anomaly Detection.” Intuit I.A.T. Lab, August 2017. 

      “Tunable Efficient Unitary Neural Networks.” International Computer Science Institute (ICSI), July 2017. 

      “Simons Institute: Representation Learning.” Intuit IAT Lab, July 2017. 

      “Complex-Valued Deep Neural Networks: Activation Functions.” Machine Learning at Berkeley, May 2017. 

      “Complex-Valued Deep Neural Networks”. Machine Learning at Berkeley, January 2017. 

      “Sound Classification with Complex Valued Neural Networks.” Machine Learning at Berkeley, November 2016. 

      “Environmental Sound Classification with Convolutional Neural Networks.” International Computer Science Institute, September 2016.
 -->

      <script type="text/javascript">
      var gaJsHost = (("https:" == document.location.protocol) ? "https://ssl." : "http://www.");
          document.write(unescape("%3Cscript src='" + gaJsHost + "google-analytics.com/ga.js' type='text/javascript'%3E%3C/script%3E"));

      </script> <script type="text/javascript">
      try {
          var pageTracker = _gat._getTracker("UA-7580334-1");
          pageTracker._trackPageview();
          } catch(err) {}
      </script>
    </td>
    </tr>
  </table>
  </body>
</html>
